{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0a0f52",
   "metadata": {},
   "source": [
    "NER and RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import os\n",
    "import html\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import html\n",
    "\n",
    "def extract_source_act_name(root):\n",
    "    \n",
    "\n",
    "    \n",
    "    title_element = root.find(\".//title\")\n",
    "    if title_element is not None and title_element.text:\n",
    "        return html.unescape(title_element.text.strip())\n",
    "\n",
    "    \n",
    "    citation_patterns = [\n",
    "        \"This Act may be cited as\",\n",
    "        \"This Act is the\",\n",
    "        \"This Act shall be known as\",\n",
    "        \"This Act is called\",\n",
    "        \"The Short Title of this Act is\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    for para in root.iter(\"para\"):\n",
    "        for text_element in para.iter(\"text\"):\n",
    "            sentence_parts = []\n",
    "            for node in text_element.iter():\n",
    "                if node.text:\n",
    "                    sentence_parts.append(html.unescape(node.text.strip()))\n",
    "            full_text = \" \".join(sentence_parts).strip()\n",
    "\n",
    "            for pattern in citation_patterns:\n",
    "                if pattern in full_text:\n",
    "                    act_title = full_text.split(pattern, 1)[-1].strip()\n",
    "                    return act_title.rstrip(\".\")\n",
    "\n",
    "    return None  \n",
    "\n",
    "\n",
    "def load_official_act_patterns(csv_file):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
    "        unique_names = sorted(df[\"Extracted Text\"].dropna().unique(), key=len, reverse=True)\n",
    "        return [(name, re.compile(rf\"\\b{re.escape(name)}\\b\", re.IGNORECASE)) for name in unique_names]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def extract_all_act_names(text, compiled_patterns):\n",
    "    \n",
    "    extracted_acts = set()\n",
    "\n",
    "    for name, pattern in compiled_patterns:\n",
    "        if pattern.search(text):\n",
    "            is_substring = any(longer_act for longer_act in extracted_acts if name in longer_act)\n",
    "            if not is_substring:\n",
    "                extracted_acts.add(name)\n",
    "\n",
    "    return list(extracted_acts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_act_name(name):\n",
    "    return name.lower().replace(\"’\", \"'\").replace(\"  \", \" \").strip()\n",
    "\n",
    "def find_principal_act_name(root, all_elements):\n",
    "    \n",
    "    namespaces = {'atidlm': 'http://www.arbortext.com/namespace/atidlm'}\n",
    "\n",
    "    \n",
    "    for elem in all_elements:\n",
    "        if elem.tag.endswith(\"para\"):\n",
    "            text = \"\".join(elem.itertext()).strip().lower()\n",
    "            if \"is called the principal act\" in text:\n",
    "                citation_elem = elem.find(\".//{*}citation\")\n",
    "                if citation_elem is not None:\n",
    "                    link = citation_elem.find(\".//atidlm:link\", namespaces)\n",
    "                    if link is not None:\n",
    "                        name = link.attrib.get(\"{http://www.arbortext.com/namespace/atidlm}name\")\n",
    "                        if name:\n",
    "                            return name\n",
    "\n",
    "    \n",
    "    for elem in all_elements:\n",
    "        if elem.tag.endswith(\"para\"):\n",
    "            text = \"\".join(elem.itertext()).strip().lower()\n",
    "            if \"this act may be cited as\" in text and \"principal act\" in text:\n",
    "                citation_elem = elem.find(\".//{*}citation\")\n",
    "                if citation_elem is not None:\n",
    "                    link = citation_elem.find(\".//atidlm:link\", namespaces)\n",
    "                    if link is not None:\n",
    "                        name = link.attrib.get(\"{http://www.arbortext.com/namespace/atidlm}name\")\n",
    "                        if name:\n",
    "                            return name\n",
    "\n",
    "    \n",
    "    for long_title in root.findall(\".//long-title\"):\n",
    "        para = long_title.find(\".//para\")\n",
    "        if para is not None:\n",
    "            text = \"\".join(para.itertext()).strip().lower()\n",
    "            if \"an act to amend the\" in text:\n",
    "                citation_elem = para.find(\".//{*}citation\")\n",
    "                if citation_elem is not None:\n",
    "                    link = citation_elem.find(\".//atidlm:link\", namespaces)\n",
    "                    if link is not None:\n",
    "                        name = link.attrib.get(\"{http://www.arbortext.com/namespace/atidlm}name\")\n",
    "                        if name:\n",
    "                            return name\n",
    "\n",
    "    \n",
    "    for elem in all_elements:\n",
    "        if elem.tag.endswith(\"para\"):\n",
    "            text = \"\".join(elem.itertext()).strip().lower()\n",
    "            if \"this act amends the\" in text and \"the principal act\" in text:\n",
    "                citation_elem = elem.find(\".//{*}citation\")\n",
    "                if citation_elem is not None:\n",
    "                    link = citation_elem.find(\".//atidlm:link\", namespaces)\n",
    "                    if link is not None:\n",
    "                        name = link.attrib.get(\"{http://www.arbortext.com/namespace/atidlm}name\")\n",
    "                        if name:\n",
    "                            return name\n",
    "                    leg_title = citation_elem.find(\".//leg-title\")\n",
    "                    if leg_title is not None and leg_title.text:\n",
    "                        return leg_title.text.strip()\n",
    "\n",
    "    \n",
    "    for elem in all_elements:\n",
    "        if elem.tag.endswith(\"text\"):\n",
    "            text_content = \"\".join(elem.itertext()).strip().lower()\n",
    "            if text_content.startswith(\"this act amends the\"):\n",
    "                citation_elem = elem.find(\".//{*}citation\")\n",
    "                if citation_elem is not None:\n",
    "                    link = citation_elem.find(\".//atidlm:link\", namespaces)\n",
    "                    if link is not None:\n",
    "                        name = link.attrib.get(\"{http://www.arbortext.com/namespace/atidlm}name\")\n",
    "                        if name:\n",
    "                            return name\n",
    "\n",
    "    \n",
    "    for elem in all_elements:\n",
    "        if elem.tag.endswith(\"para\"):\n",
    "            text = \"\".join(elem.itertext()).strip().lower()\n",
    "            if \"is called\" in text and \"the principal act\" in text:\n",
    "                citation_elem = elem.find(\".//{*}citation\")\n",
    "                if citation_elem is not None:\n",
    "                    link = citation_elem.find(\".//atidlm:link\", namespaces)\n",
    "                    if link is not None:\n",
    "                        name = link.attrib.get(\"{http://www.arbortext.com/namespace/atidlm}name\")\n",
    "                        if name:\n",
    "                            return name\n",
    "                            \n",
    "    for elem in root.findall(\".//subprov\"):\n",
    "        para = elem.find(\".//para\")\n",
    "        if para is not None:\n",
    "            para_text = \"\".join(para.itertext()).strip().lower()\n",
    "            if \"this\" in para_text and \"amends the\" in para_text and \"principal act\" in para_text:\n",
    "                leg_title = para.find(\".//leg-title\")\n",
    "                if leg_title is not None and leg_title.text:\n",
    "                    return leg_title.text.strip()\n",
    "    \n",
    "    for para in root.findall(\".//para\"):\n",
    "        para_text = \"\".join(para.itertext()).strip().lower()\n",
    "        if \"this act amends the\" in para_text:\n",
    "            citation_elem = para.find(\".//citation\")\n",
    "            if citation_elem is not None:\n",
    "                leg_title = citation_elem.find(\"leg-title\")\n",
    "                if leg_title is not None and leg_title.text:\n",
    "                    return leg_title.text.strip()\n",
    "                else:\n",
    "                    return \"\".join(citation_elem.itertext()).strip()\n",
    "\n",
    "\n",
    "    return None  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "substitution_keywords = {\"substituted\", \"replaced with\", \"to read as\", \"replacement for\"}\n",
    "\n",
    "def determine_relation_type_from_para(text, default=\"AMD_S\"):\n",
    "    text = text.lower()\n",
    "    return \"CIT\" if any(kw in text for kw in substitution_keywords) else default\n",
    "\n",
    "\n",
    "def get_amends_affect_citations(root):\n",
    "    \n",
    "    excluded_amendment_elements = set()\n",
    "    amendment_keywords = (\"amendment to\", \"amendments to\")\n",
    "\n",
    "    \n",
    "    for amends_affect in root.findall(\".//amends-affect\"):\n",
    "        for citation in amends_affect.findall(\".//citation\"):\n",
    "            excluded_amendment_elements.add(citation)\n",
    "\n",
    "    \n",
    "    for schedule_amendment in root.findall(\".//schedule-amendments\"):\n",
    "        for para in schedule_amendment.findall(\".//para\"):\n",
    "            para_text = \"\".join(para.itertext() or \"\").lower()\n",
    "            if any(kw in para_text for kw in amendment_keywords):\n",
    "                excluded_amendment_elements.add(para)\n",
    "\n",
    "    return excluded_amendment_elements\n",
    "\n",
    "\n",
    "def get_history_note_elements(root):\n",
    "\n",
    "    history_note_elements = set()\n",
    "\n",
    "    for history_note in root.findall(\".//history-note\"):\n",
    "        for elem in history_note.iter():\n",
    "            history_note_elements.add(elem)\n",
    "\n",
    "    return history_note_elements\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def extract_amended_acts_1(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"enactments amended\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"./heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        extracted_acts = extract_all_act_names(heading_element.text, compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_consequential_amendments_schedule_group2(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"consequential amendments\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        extracted_acts = extract_all_act_names(heading_element.text.strip(), compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "def extract_repealed_acts_1(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"enactments repealed\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"./heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        extracted_acts = extract_all_act_names(heading_element.text, compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"R_S\")\n",
    "\n",
    "\n",
    "   \n",
    "def extract_amended_acts(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"enactments amended\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"./heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        extracted_acts = extract_all_act_names(heading_element.text, compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "def extract_repealed_acts(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"enactments repealed\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"./heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        extracted_acts = extract_all_act_names(heading_element.text, compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"R_S\")\n",
    "def extract_amended_acts_from_headings(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "        \n",
    "        if tag_name == \"heading\" and element.text:\n",
    "            heading_text = element.text.strip()\n",
    "            if \"amended\" in heading_text.lower():\n",
    "                extracted_acts = extract_all_act_names(heading_text, compiled_act_patterns)\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "def extract_consequential_amendments1(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    \n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        \n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        \n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"consequential amendments to other enactments\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"./heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        extracted_acts = extract_all_act_names(heading_element.text, compiled_act_patterns)\n",
    "\n",
    "                        \n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_legtable_amendments(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag == \"amend\":\n",
    "            \n",
    "            heading_element = element.find(\"heading\")\n",
    "            amended_acts = []\n",
    "            if heading_element is not None and heading_element.text:\n",
    "                amended_acts = extract_all_act_names(heading_element.text.strip(), compiled_act_patterns)\n",
    "\n",
    "            for act in amended_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_other_enactments_amended(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None  \n",
    "\n",
    "    for element in all_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        \n",
    "        if tag_name == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        \n",
    "        elif tag_name == \"schedule.amendments\" and last_heading_text:\n",
    "            if \"other enactments amended\" in last_heading_text:\n",
    "                for group2 in element.findall(\".//schedule.amendments.group2\"):\n",
    "                    heading_element = group2.find(\"./heading\")\n",
    "                    if heading_element is not None and heading_element.text:\n",
    "                        amended_act_text = heading_element.text.strip()\n",
    "                        extracted_acts = extract_all_act_names(amended_act_text, compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "def extract_citations(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "\n",
    "    allowed_tags = {\"extref\", \"leg-title\", \"intref\"}  \n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        tag_name = element.tag.lower()\n",
    "\n",
    "        if tag_name == \"citation\":\n",
    "            citation_text_parts = []\n",
    "\n",
    "            \n",
    "            leg_title_element = element.find(\".//leg-title\")\n",
    "            if leg_title_element is not None and leg_title_element.text:\n",
    "                citation_text_parts.append(leg_title_element.text.strip())\n",
    "            else:\n",
    "                for node in element.iter():\n",
    "                    if node.tag in allowed_tags and node.text:\n",
    "                        citation_text_parts.append(node.text.strip())\n",
    "\n",
    "            full_citation_text = \" \".join(citation_text_parts).strip()\n",
    "            full_context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "\n",
    "            \n",
    "            if \"amendment to\" in full_context_text or \"amendments to\" in full_context_text:\n",
    "                continue\n",
    "\n",
    "            extracted_acts = extract_all_act_names(full_citation_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "def extract_para_citations(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "\n",
    "    allowed_tags = {\"extref\", \"leg-title\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"para\":\n",
    "            para_text_context = \"\".join(element.itertext() or \"\").lower()\n",
    "\n",
    "            \n",
    "            if \"amendment to\" in para_text_context or \"amendments to\" in para_text_context:\n",
    "                continue\n",
    "\n",
    "            for citation_element in element.findall(\".//citation\"):\n",
    "                citation_text_parts = []\n",
    "\n",
    "                for node in citation_element.iter():\n",
    "                    if node.tag in allowed_tags and node.text:\n",
    "                        citation_text_parts.append(node.text.strip())\n",
    "                    if node.tail and node.tag in allowed_tags:\n",
    "                        citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "                full_text = \" \".join(citation_text_parts).strip()\n",
    "                extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_cf_and_def_term_citations1(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\", \"leg-title\", \"intref\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag in {\"cf\", \"def-term\"}:\n",
    "            if hasattr(element, \"iterancestors\") and any(p.tag == \"history-note\" for p in element.iterancestors()):\n",
    "                continue\n",
    "\n",
    "            element_text_context = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in element_text_context or \"amendments to\" in element_text_context:\n",
    "                continue\n",
    "\n",
    "            extracted_acts = set()\n",
    "\n",
    "            if element.text:\n",
    "                direct_text = element.text.strip()\n",
    "                extracted_acts.update(extract_all_act_names(direct_text, compiled_act_patterns))\n",
    "\n",
    "            text_element = element.find(\"./text\")\n",
    "            if text_element is not None and text_element.text:\n",
    "                text_content = text_element.text.strip()\n",
    "                extracted_acts.update(extract_all_act_names(text_content, compiled_act_patterns))\n",
    "\n",
    "            citation_element = element.find(\".//citation\")\n",
    "            if citation_element is not None:\n",
    "                citation_text_parts = []\n",
    "                for node in citation_element.iter():\n",
    "                    if node.tag in allowed_tags and node.text:\n",
    "                        citation_text_parts.append(node.text.strip())\n",
    "                    if node.tail and node.tag in allowed_tags:\n",
    "                        citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "                full_citation_text = \" \".join(citation_text_parts).strip()\n",
    "                extracted_acts.update(extract_all_act_names(full_citation_text, compiled_act_patterns))\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_cf_and_def_term_citations(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\", \"leg-title\", \"intref\"}\n",
    "    skip_keywords = {\n",
    "        \"amendment to\", \"amendments to\", \"inserted\", \"repealed\", \"amended\",\n",
    "        \"substituted\", \"replaced\", \"remove\", \"omit\"\n",
    "    }\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag in {\"cf\", \"def-term\"}:\n",
    "            if hasattr(element, \"iterancestors\") and any(p.tag == \"history-note\" for p in element.iterancestors()):\n",
    "                continue\n",
    "\n",
    "            \n",
    "            element_text_context = \"\".join(element.itertext() or \"\").lower()\n",
    "            if any(keyword in element_text_context for keyword in skip_keywords):\n",
    "                continue\n",
    "\n",
    "            extracted_acts = set()\n",
    "\n",
    "            if element.text:\n",
    "                direct_text = element.text.strip()\n",
    "                extracted_acts.update(extract_all_act_names(direct_text, compiled_act_patterns))\n",
    "\n",
    "            text_element = element.find(\"./text\")\n",
    "            if text_element is not None and text_element.text:\n",
    "                text_content = text_element.text.strip()\n",
    "                extracted_acts.update(extract_all_act_names(text_content, compiled_act_patterns))\n",
    "\n",
    "            citation_element = element.find(\".//citation\")\n",
    "            if citation_element is not None:\n",
    "                citation_text_parts = []\n",
    "                for node in citation_element.iter():\n",
    "                    if node.tag in allowed_tags and node.text:\n",
    "                        citation_text_parts.append(node.text.strip())\n",
    "                    if node.tail and node.tag in allowed_tags:\n",
    "                        citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "                full_citation_text = \" \".join(citation_text_parts).strip()\n",
    "                extracted_acts.update(extract_all_act_names(full_citation_text, compiled_act_patterns))\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_paras_1(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "\n",
    "    allowed_tags = {\"extref\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"para\":\n",
    "            para_context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "\n",
    "            \n",
    "            if \"amendment to\" in para_context_text or \"amendments to\" in para_context_text:\n",
    "                continue\n",
    "\n",
    "            for citation in element.findall(\".//citation\"):\n",
    "                citation_text_parts = []\n",
    "\n",
    "                for node in citation.iter():\n",
    "                    if node.tag in allowed_tags and node.text:\n",
    "                        citation_text_parts.append(node.text.strip())\n",
    "                    if node.tail and node.tag in allowed_tags:\n",
    "                        citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "                full_citation_text = \" \".join(citation_text_parts).strip()\n",
    "                extracted_acts = extract_all_act_names(full_citation_text, compiled_act_patterns)\n",
    "\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_headings_with_section(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    exclusion_keywords = {\"amend\", \"amendment\", \"amendments\", \"repeal\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"heading\" and element.text:\n",
    "            heading_text = element.text.strip().lower()\n",
    "\n",
    "            if \"under section\" in heading_text and not any(excl in heading_text for excl in exclusion_keywords):\n",
    "                extracted_acts = extract_all_act_names(heading_text, compiled_act_patterns)\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_leg_title1(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"leg-title\" and element.text:\n",
    "            parent_chain = list(element.iterancestors()) if hasattr(element, \"iterancestors\") else []\n",
    "\n",
    "            if any(p.tag == \"citation\" for p in parent_chain):\n",
    "                citation_root = next((p for p in parent_chain if p.tag == \"citation\"), None)\n",
    "\n",
    "                \n",
    "                context_text = \"\".join(citation_root.itertext() or \"\").lower() if citation_root is not None else \"\"\n",
    "                if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                    continue\n",
    "\n",
    "                act_text = element.text.strip()\n",
    "                extracted_acts = extract_all_act_names(act_text, compiled_act_patterns)\n",
    "\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_insertwords(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"insertwords\":\n",
    "            insertwords_context = \"\".join(element.itertext() or \"\").lower()\n",
    "\n",
    "            \n",
    "            if \"amendment to\" in insertwords_context or \"amendments to\" in insertwords_context:\n",
    "                continue\n",
    "\n",
    "            for citation in element.findall(\".//citation\"):\n",
    "                leg_title = citation.find(\"leg-title\")\n",
    "                if leg_title is not None and leg_title.text:\n",
    "                    act_text = leg_title.text.strip()\n",
    "                    extracted_acts = extract_all_act_names(act_text, compiled_act_patterns)\n",
    "\n",
    "                    for act in extracted_acts:\n",
    "                        if act != source_act_name:\n",
    "                            relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_legtitle_citations(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            citation_context = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in citation_context or \"amendments to\" in citation_context:\n",
    "                continue\n",
    "\n",
    "            leg_title = element.find(\"leg-title\")\n",
    "            if leg_title is not None and leg_title.text:\n",
    "                act_text = leg_title.text.strip()\n",
    "                extracted_acts = extract_all_act_names(act_text, compiled_act_patterns)\n",
    "\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_extref_and_text(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            for node in element.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "def extract_multiple_citations_in_para(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\", \"leg-title\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            for node in element.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_with_intref_and_legtitle(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"leg-title\", \"extref\", \"intref\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            for node in element.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_with_insertwords_and_multiple_extrefs(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\", \"leg-title\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            for node in element.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_def_para(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"leg-title\", \"extref\", \"intref\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            if hasattr(element, \"iterancestors\") and any(p.tag == \"history-note\" for p in element.iterancestors()):\n",
    "                continue\n",
    "\n",
    "            \n",
    "            parent_chain = list(element.iterancestors()) if hasattr(element, \"iterancestors\") else []\n",
    "            if not any(p.tag == \"def-para\" for p in parent_chain):\n",
    "                continue\n",
    "\n",
    "            \n",
    "            context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            citation_text_parts = []\n",
    "            for node in element.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_leg_title(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"leg-title\" and element.text:\n",
    "            parent_chain = list(element.iterancestors()) if hasattr(element, \"iterancestors\") else []\n",
    "            if any(p.tag == \"citation\" for p in parent_chain):\n",
    "                citation_parent = next((p for p in parent_chain if p.tag == \"citation\"), None)\n",
    "\n",
    "        \n",
    "                context_text = \"\".join(citation_parent.itertext() or \"\").lower() if citation_parent is not None else \"\"\n",
    "                if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                    continue\n",
    "\n",
    "                act_text = element.text.strip()\n",
    "                extracted_acts = extract_all_act_names(act_text, compiled_act_patterns)\n",
    "\n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_from_extref_with_trailing_act_name(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\", \"intref\", \"leg-title\"}\n",
    "\n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"citation\":\n",
    "            \n",
    "            context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            \n",
    "            for node in element.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            \n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_citations_with_extref_and_intref(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"extref\", \"intref\", \"leg-title\"}\n",
    "\n",
    "    for citation in  filtered_elements:\n",
    "        if citation.tag == \"citation\":\n",
    "        \n",
    "            context_text = \"\".join(citation.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            \n",
    "            for node in citation.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_dual_citations_leg_title_and_extref(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    allowed_tags = {\"leg-title\", \"extref\", \"intref\"}\n",
    "\n",
    "    for citation in  filtered_elements:\n",
    "        if citation.tag == \"citation\":\n",
    "            \n",
    "            context_text = \"\".join(citation.itertext() or \"\").lower()\n",
    "            if \"amendment to\" in context_text or \"amendments to\" in context_text:\n",
    "                continue\n",
    "\n",
    "            citation_text_parts = []\n",
    "\n",
    "            \n",
    "            for node in citation.iter():\n",
    "                if node.tag in allowed_tags and node.text:\n",
    "                    citation_text_parts.append(node.text.strip())\n",
    "                if node.tail and node.tag in allowed_tags:\n",
    "                    citation_text_parts.append(node.tail.strip())\n",
    "\n",
    "            full_text = \" \".join(citation_text_parts).strip()\n",
    "            extracted_acts = extract_all_act_names(full_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_plaintext_act_references(filtered_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in  filtered_elements:\n",
    "        if element.tag == \"para\":\n",
    "            para_context_text = \"\".join(element.itertext() or \"\").lower()\n",
    "\n",
    "            \n",
    "            if \"amendment to\" in para_context_text or \"amendments to\" in para_context_text:\n",
    "                continue\n",
    "\n",
    "            for text_elem in element.findall(\".//text\"):\n",
    "                if text_elem.text:\n",
    "                    plain_text = text_elem.text.strip()\n",
    "                    extracted_acts = extract_all_act_names(plain_text, compiled_act_patterns)\n",
    "\n",
    "                    for act in extracted_acts:\n",
    "                        if act != source_act_name:\n",
    "                            relations[(source_act_name, act)][\"relation_types\"].add(\"CIT\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_amendments_from_crossheadings(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag.lower() == \"crosshead\" and element.text:\n",
    "            if \"amendments\" in element.text.lower():\n",
    "                heading_text = element.text.strip()\n",
    "                extracted_acts = extract_all_act_names(heading_text, compiled_act_patterns)\n",
    "                \n",
    "                for act in extracted_acts:\n",
    "                    if act != source_act_name:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "def extract_schedule_repeals_after_amendments_crosshead(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    found_amendment_crosshead = False\n",
    "\n",
    "    for element in all_elements:\n",
    "        tag = element.tag.lower()\n",
    "\n",
    "        \n",
    "        if tag == \"crosshead\" and element.text and \"amendments\" in element.text.lower():\n",
    "            found_amendment_crosshead = True\n",
    "\n",
    "        \n",
    "        elif found_amendment_crosshead and tag == \"heading\" and element.text and \"repeal\" in element.text.lower():\n",
    "            heading_text = element.text.strip()\n",
    "            extracted_acts = extract_all_act_names(heading_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"PR_S\")\n",
    "\n",
    "\n",
    "def extract_consequential_amendments(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag.lower() == \"heading\" and element.text and \"consequential amendments\" in element.text.lower():\n",
    "            heading_text = element.text.strip()\n",
    "            extracted_acts = extract_all_act_names(heading_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "def extract_schedule_repeals_and_citations(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag == \"schedule.amendments.group1\":\n",
    "            group1_heading = element.find(\"./heading\")\n",
    "\n",
    "            if group1_heading is not None and group1_heading.text:\n",
    "                heading_text = group1_heading.text.strip()\n",
    "                if \"repeals relating to\" in heading_text.lower():\n",
    "                    \n",
    "                    \n",
    "                    for group2 in element.findall(\"./schedule.amendments.group2\"):\n",
    "                        group2_heading = group2.find(\"./heading\")\n",
    "                        if group2_heading is not None and group2_heading.text:\n",
    "                            group2_text = group2_heading.text.strip()\n",
    "                            repealed_acts = extract_all_act_names(group2_text, compiled_act_patterns)\n",
    "\n",
    "                            for act in repealed_acts:\n",
    "                                if act != source_act_name:\n",
    "                                    relations[(source_act_name, act)][\"relation_types\"].add(\"R_S\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_amendments(all_elements, source_act_name, compiled_act_patterns, relations): \n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag.lower() == \"history-note\":\n",
    "            amending_leg_text = \"\".join(element.itertext()).strip()\n",
    "            extracted_acts = extract_all_act_names(amending_leg_text, compiled_act_patterns)\n",
    "\n",
    "            amending_operation_element = element.find(\".//amending-operation\")\n",
    "            operation_text = (\n",
    "                amending_operation_element.text.strip().lower()\n",
    "                if amending_operation_element is not None and amending_operation_element.text\n",
    "                else \"\"\n",
    "            )\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    if \"repealed\" in operation_text:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"PR\")\n",
    "                    else:\n",
    "                        relations[(source_act_name, act)][\"relation_types\"].add(\"AMD\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_amendment_headings(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag.lower() == \"heading\" and element.text and \"amendments\" in element.text.lower():\n",
    "            heading_text = element.text.strip()\n",
    "            extracted_acts = extract_all_act_names(heading_text, compiled_act_patterns)\n",
    "\n",
    "            for act in extracted_acts:\n",
    "                if act != source_act_name:\n",
    "                    relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_consequential_amends_affect_amendments(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None\n",
    "\n",
    "    for element in all_elements:\n",
    "        tag = element.tag.lower()\n",
    "\n",
    "        if tag in {\"heading\", \"crosshead\"}:\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag == \"amends-affect\" and last_heading_text and \"consequential amendments\" in last_heading_text:\n",
    "            for citation in element.findall(\".//citation\"):\n",
    "                for leg_title in citation.findall(\"leg-title\"):\n",
    "                    if leg_title is not None and leg_title.text:\n",
    "                        act_name = leg_title.text.strip()\n",
    "                        extracted_acts = extract_all_act_names(act_name, compiled_act_patterns)\n",
    "                        for act in extracted_acts:\n",
    "                            if act != source_act_name:\n",
    "                                relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_schedule_amendments_with_amend_block(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for element in all_elements:\n",
    "        if element.tag.lower() == \"schedule.amendments.group2\":\n",
    "            heading_element = element.find(\"heading\")\n",
    "            if heading_element is not None and heading_element.text:\n",
    "                if element.find(\".//amend\") is not None:\n",
    "                    act_heading_text = heading_element.text.strip()\n",
    "                    extracted_acts = extract_all_act_names(act_heading_text, compiled_act_patterns)\n",
    "                    for act in extracted_acts:\n",
    "                        if act != source_act_name:\n",
    "                            relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_consequential_repeals_from_schedule_misc(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None\n",
    "\n",
    "    for element in all_elements:\n",
    "        tag = element.tag.lower()\n",
    "\n",
    "        if tag == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag == \"schedule.misc\" and last_heading_text and \"consequential repeals\" in last_heading_text:\n",
    "            for head5 in element.findall(\".//head5\"):\n",
    "                heading_elem = head5.find(\"heading\")\n",
    "                if heading_elem is not None and heading_elem.text:\n",
    "                    act_heading_text = heading_elem.text.strip()\n",
    "                    extracted_acts = extract_all_act_names(act_heading_text, compiled_act_patterns)\n",
    "\n",
    "                    for act in extracted_acts:\n",
    "                        if act != source_act_name:\n",
    "                            relations[(source_act_name, act)][\"relation_types\"].add(\"R_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_enactments_amended_from_schedule_misc(all_elements, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    last_heading_text = None\n",
    "\n",
    "    for element in all_elements:\n",
    "        tag = element.tag.lower()\n",
    "\n",
    "        if tag == \"heading\":\n",
    "            last_heading_text = element.text.strip().lower() if element.text else None\n",
    "\n",
    "        elif tag == \"schedule.misc\" and last_heading_text and \"enactments amended\" in last_heading_text:\n",
    "            for head5 in element.findall(\".//head5\"):\n",
    "                heading_elem = head5.find(\"heading\")\n",
    "                if heading_elem is not None and heading_elem.text:\n",
    "                    act_heading_text = heading_elem.text.strip()\n",
    "                    extracted_acts = extract_all_act_names(act_heading_text, compiled_act_patterns)\n",
    "                    \n",
    "                    for act in extracted_acts:\n",
    "                        if act != source_act_name:\n",
    "                            relations[(source_act_name, act)][\"relation_types\"].add(\"AMD_S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_amds_amendment_with_substitution_plaintext(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "    \n",
    "    for elem in filtered_elements_for_history_sensitive:\n",
    "        if not elem.tag or not elem.tag.endswith(\"para\"):\n",
    "            continue\n",
    "\n",
    "        para_text = \"\".join(elem.itertext() or \"\").strip().lower()\n",
    "\n",
    "        if \"is hereby amended by repealing\" in para_text:\n",
    "            relation_type = \"PR_S\"\n",
    "        elif \"is hereby amended by substituting\" in para_text or \"is hereby substituted\" in para_text:\n",
    "            relation_type = \"AMD_S\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for citation in elem.findall(\".//citation\"):\n",
    "            citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "            principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "\n",
    "            if principal_name and principal_name != source_act_name:\n",
    "                relations[(source_act_name, principal_name)][\"relation_types\"].add(relation_type)\n",
    "\n",
    "            for name, pattern in compiled_act_patterns:\n",
    "                if pattern.search(citation_text) and name != source_act_name:\n",
    "                    relations[(source_act_name, name)][\"relation_types\"].add(relation_type)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_repeal_relations_consolidated_safe(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "    trigger_words = {\"section\", \"part\", \"schedule\"}\n",
    "    repeal_phrases = {\n",
    "        \"is hereby consequentially repealed\",\n",
    "        \"are hereby consequentially repealed\",\n",
    "        \"the following enactments are hereby consequentially repealed\"\n",
    "    }\n",
    "\n",
    "    for elem in filtered_elements_for_history_sensitive:\n",
    "        if not elem.tag or not elem.tag.endswith(\"para\"):\n",
    "            continue\n",
    "\n",
    "        para_text = \"\".join(elem.itertext() or \"\").lower()\n",
    "\n",
    "        if not any(phrase in para_text for phrase in repeal_phrases):\n",
    "            continue\n",
    "\n",
    "        target_citation_blocks = []\n",
    "\n",
    "        if \"the following enactments are hereby consequentially repealed\" in para_text:\n",
    "            for label_para in elem.findall(\".//label-para\"):\n",
    "                for inner_para in label_para.findall(\".//para\"):\n",
    "                    target_citation_blocks.extend(inner_para.findall(\".//citation\"))\n",
    "        else:\n",
    "            target_citation_blocks.extend(elem.findall(\".//citation\"))\n",
    "\n",
    "        for citation in target_citation_blocks:\n",
    "            citation_text = \" \".join(citation.itertext() or \"\").strip().lower()\n",
    "            if not citation_text:\n",
    "                continue\n",
    "\n",
    "            relation_type = determine_relation_type_from_para(\n",
    "                para_text,\n",
    "                default=\"PR_S\" if any(w in citation_text for w in trigger_words) else \"R_S\"\n",
    "            )\n",
    "\n",
    "            principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "            \n",
    "\n",
    "            if principal_name and principal_name != source_act_name:\n",
    "                relations[(source_act_name, principal_name)][\"relation_types\"].add(relation_type)\n",
    "                \n",
    "\n",
    "            for name, pattern in compiled_act_patterns:\n",
    "                if pattern.search(citation_text) and name != source_act_name:\n",
    "                    relations[(source_act_name, name)][\"relation_types\"].add(relation_type)\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "def extract_amendment_with_relates_to_plain(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "    for elem in filtered_elements_for_history_sensitive:\n",
    "        if elem.tag and elem.tag.endswith(\"subprov\"):\n",
    "            para = elem.find(\".//para\")\n",
    "            if para is not None:\n",
    "                para_text = \"\".join(text or \"\" for text in para.itertext()).lower()\n",
    "\n",
    "                if any(phrase in para_text for phrase in [\"is hereby consequentially amended\", \"substituted\"]):\n",
    "                    relation_type = determine_relation_type_from_para(para_text, default=\"AMD_S\")\n",
    "\n",
    "                    citations = para.findall(\".//citation\")\n",
    "                    for citation in citations:\n",
    "                        citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "                        principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "                        \n",
    "\n",
    "                        if principal_name and principal_name != source_act_name:\n",
    "                            relations[(source_act_name, principal_name)][\"relation_types\"].add(relation_type)\n",
    "                            \n",
    "\n",
    "                        for name, pattern in compiled_act_patterns:\n",
    "                            if pattern.search(citation_text) and name != source_act_name:\n",
    "                                relations[(source_act_name, name)][\"relation_types\"].add(relation_type)\n",
    "                                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_amendment_special_from_para_plain(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "\n",
    "    for elem in filtered_elements_for_history_sensitive:\n",
    "        if elem.tag and elem.tag.endswith(\"para\"):\n",
    "            para_text = \"\".join(text or \"\" for text in elem.itertext()).lower()\n",
    "\n",
    "            if \"hereby consequentially amended\" in para_text:\n",
    "                citations = elem.findall(\".//citation\")\n",
    "\n",
    "                for citation in citations:\n",
    "                    citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "                    principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "\n",
    "                    \n",
    "\n",
    "                    if principal_name and principal_name != source_act_name:\n",
    "                        relations[(source_act_name, principal_name)][\"relation_types\"].add(\"AMD_S\")\n",
    "                        \n",
    "\n",
    "                    for name, pattern in compiled_act_patterns:\n",
    "                        if pattern.search(citation_text) and name != source_act_name:\n",
    "                            relations[(source_act_name, name)][\"relation_types\"].add(\"AMD_S\")\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_amend_or_repeal_amendments_from_para_safe(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "    for element in filtered_elements_for_history_sensitive:\n",
    "        if element.tag and element.tag.endswith(\"para\"):\n",
    "            para_text = \"\".join(text or \"\" for text in element.itertext()).lower()\n",
    "\n",
    "            if \"is amended by\" in para_text:\n",
    "                \n",
    "                if \"the principal act is amended by repealing\" in para_text and \"substituting the following part\" in para_text:\n",
    "                    principal_name = find_principal_act_name(root, list(root.iter()))  \n",
    "                    if principal_name and principal_name != source_act_name:\n",
    "                        relations[(source_act_name, principal_name)][\"relation_types\"].add(\"PR_S\")\n",
    "                    continue  \n",
    "\n",
    "                \n",
    "                relation_type = determine_relation_type_from_para(\n",
    "                    para_text,\n",
    "                    default=\"PR_S\" if \"repeal\" in para_text else \"AMD_S\"\n",
    "                )\n",
    "\n",
    "                for citation in element.findall(\".//citation\"):\n",
    "                    citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "                    principal_name = find_principal_act_name(root, list(root.iter()))  \n",
    "\n",
    "                    \n",
    "\n",
    "                    if principal_name and principal_name != source_act_name:\n",
    "                        relations[(source_act_name, principal_name)][\"relation_types\"].add(relation_type)\n",
    "                        \n",
    "\n",
    "                    for name, pattern in compiled_act_patterns:\n",
    "                        if pattern.search(citation_text) and name != source_act_name:\n",
    "                            relations[(source_act_name, name)][\"relation_types\"].add(relation_type)\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_amds_from_amendment_heading_and_para_safe(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "    for element in filtered_elements_for_history_sensitive:\n",
    "        tag = element.tag.lower()\n",
    "\n",
    "        if tag.endswith(\"heading\") and element.text and \"amendment to\" in element.text.lower():\n",
    "            for citation in element.findall(\".//citation\"):\n",
    "                citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "                principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "\n",
    "                \n",
    "\n",
    "                if principal_name and principal_name != source_act_name:\n",
    "                    relations[(source_act_name, principal_name)][\"relation_types\"].add(\"AMD_S\")\n",
    "                    \n",
    "\n",
    "                for name, pattern in compiled_act_patterns:\n",
    "                    if pattern.search(citation_text) and name != source_act_name:\n",
    "                        relations[(source_act_name, name)][\"relation_types\"].add(\"AMD_S\")\n",
    "                        \n",
    "\n",
    "        elif tag.endswith(\"para\"):\n",
    "            para_text = \"\".join(element.itertext() or \"\").strip().lower()\n",
    "\n",
    "            if \"is amended by inserting\" in para_text or \"is amended by adding\" in para_text:\n",
    "                relation_type = determine_relation_type_from_para(para_text, default=\"AMD_S\")\n",
    "\n",
    "                for citation in element.findall(\".//citation\"):\n",
    "                    citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "                    principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "\n",
    "                    \n",
    "\n",
    "                    if principal_name and principal_name != source_act_name:\n",
    "                        relations[(source_act_name, principal_name)][\"relation_types\"].add(relation_type)\n",
    "                       \n",
    "\n",
    "                    for name, pattern in compiled_act_patterns:\n",
    "                        if pattern.search(citation_text) and name != source_act_name:\n",
    "                            relations[(source_act_name, name)][\"relation_types\"].add(relation_type)\n",
    "                           \n",
    "\n",
    "\n",
    "def extract_intro_amendment_relation(root, filtered_elements_for_history_sensitive, source_act_name, compiled_act_patterns, relations):\n",
    "    for element in filtered_elements_for_history_sensitive:\n",
    "        if element.tag.lower().endswith(\"para\"):\n",
    "            para_text = \"\".join(element.itertext() or \"\").strip().lower()\n",
    "\n",
    "            if \"this act amends the\" in para_text:\n",
    "                relation_type = determine_relation_type_from_para(para_text, default=\"AMD_S\")\n",
    "\n",
    "                for citation in element.findall(\".//citation\"):\n",
    "                    citation_text = \"\".join(citation.itertext() or \"\").strip().lower()\n",
    "                    principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "\n",
    "                    \n",
    "\n",
    "                    if principal_name and principal_name != source_act_name:\n",
    "                        relations[(source_act_name, principal_name)][\"relation_types\"].add(relation_type)\n",
    "                       \n",
    "\n",
    "                    for name, pattern in compiled_act_patterns:\n",
    "                        if pattern.search(citation_text) and name != source_act_name:\n",
    "                            relations[(source_act_name, name)][\"relation_types\"].add(relation_type)\n",
    "                           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_acts_and_relations(xml_file, official_act_names):\n",
    "    \n",
    "    relations = defaultdict(lambda: {\"relation_types\": set(), \"dates\": set()})\n",
    "    act_names = set()\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        all_elements = list(root.iter())  \n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML file: {e}\")\n",
    "        return set(), relations, None\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    source_act_name = extract_source_act_name(root)\n",
    "\n",
    "\n",
    "    \n",
    "    if not source_act_name:\n",
    "        source_act_name = os.path.splitext(os.path.basename(xml_file))[0]\n",
    "\n",
    "    act_names.add(source_act_name)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    skip_elements = get_amends_affect_citations(root)\n",
    "    filtered_elements = [el for el in root.iter() if el not in skip_elements]\n",
    "    history_skip_elements = get_history_note_elements(root)\n",
    "    filtered_elements_for_history_sensitive = [el for el in root.iter() if el not in history_skip_elements]\n",
    "\n",
    "\n",
    "\n",
    "    principal_name = find_principal_act_name(root, filtered_elements_for_history_sensitive)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if principal_name:\n",
    "         print(f\"📘 Principal act detected: {principal_name}\")  \n",
    "\n",
    "         extract_consequential_repeals_from_schedule_misc(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_repealed_acts(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_schedule_repeals_after_amendments_crosshead(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_repealed_acts_1(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_schedule_repeals_and_citations(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_amended_acts_1(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_other_enactments_amended(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_consequential_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_amended_acts(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_enactments_amended_from_schedule_misc(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_amendment_headings(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_amendments_from_crossheadings(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_consequential_amends_affect_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_consequential_amendments_schedule_group2(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_legtable_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_schedule_amendments_with_amend_block(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_amended_acts_from_headings(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "         extract_consequential_amendments1(all_elements, source_act_name, official_act_names, relations)\n",
    "\n",
    "\n",
    "\n",
    "         extract_citations_from_legtitle_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_para_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_insertwords(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_cf_and_def_term_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_paras_1(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_leg_title(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_headings_with_section(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_extref_and_text(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_multiple_citations_in_para(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_with_insertwords_and_multiple_extrefs(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_cf_and_def_term_citations1(filtered_elements, source_act_name, official_act_names, relations)\n",
    "    \n",
    "\n",
    "         extract_citations_with_intref_and_legtitle(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_def_para(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_extref_with_trailing_act_name(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_from_leg_title1(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations_with_extref_and_intref(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_dual_citations_leg_title_and_extref(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_plaintext_act_references(filtered_elements, source_act_name, official_act_names, relations)\n",
    "         extract_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "\n",
    "         \n",
    "         extract_amds_amendment_with_substitution_plaintext(root, filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "         extract_repeal_relations_consolidated_safe(root, filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "         extract_amendment_with_relates_to_plain(root, filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "         extract_amend_or_repeal_amendments_from_para_safe(root,filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "         extract_amendment_special_from_para_plain(root, filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "         extract_amds_from_amendment_heading_and_para_safe(root, filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "         extract_intro_amendment_relation(root, filtered_elements_for_history_sensitive, source_act_name, official_act_names, relations)\n",
    "\n",
    "  \n",
    "    else:\n",
    "        extract_consequential_repeals_from_schedule_misc(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_repealed_acts(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_schedule_repeals_after_amendments_crosshead(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_repealed_acts_1(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_schedule_repeals_and_citations(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_amended_acts_1(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_other_enactments_amended(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_consequential_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_amended_acts(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_enactments_amended_from_schedule_misc(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_amendment_headings(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_amendments_from_crossheadings(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_consequential_amends_affect_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_consequential_amendments_schedule_group2(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_legtable_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_schedule_amendments_with_amend_block(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_amended_acts_from_headings(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_amendments(all_elements, source_act_name, official_act_names, relations)\n",
    "        extract_consequential_amendments1(all_elements, source_act_name, official_act_names, relations)\n",
    "\n",
    "\n",
    "\n",
    "        extract_citations_from_legtitle_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_para_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_insertwords(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_cf_and_def_term_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_paras_1(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_leg_title(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_headings_with_section(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_extref_and_text(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_multiple_citations_in_para(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_with_insertwords_and_multiple_extrefs(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_cf_and_def_term_citations1(filtered_elements, source_act_name, official_act_names, relations)\n",
    "    \n",
    "\n",
    "        extract_citations_with_intref_and_legtitle(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_def_para(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_extref_with_trailing_act_name(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_from_leg_title1(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations_with_extref_and_intref(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_dual_citations_leg_title_and_extref(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_plaintext_act_references(filtered_elements, source_act_name, official_act_names, relations)\n",
    "        extract_citations(filtered_elements, source_act_name, official_act_names, relations)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for key, data in relations.items():\n",
    "        if \"R_S\" in data[\"relation_types\"] and \"PR_S\" in data[\"relation_types\"]:\n",
    "            data[\"relation_types\"].discard(\"PR_S\")\n",
    "\n",
    "    \n",
    "    \n",
    "    return act_names, relations\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "\n",
    "def process_folder(folder_path, compiled_act_patterns):\n",
    "    all_relations = defaultdict(lambda: {\"relation_types\": set()})\n",
    "    all_acts = set()\n",
    "\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if not file_name.endswith(\".xml\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"🔍 Processing: {file_name}\")  \n",
    "\n",
    "        xml_file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        try:\n",
    "            act_names, relations = extract_acts_and_relations(xml_file_path, compiled_act_patterns)\n",
    "            all_acts.update(act_names)\n",
    "\n",
    "            \n",
    "            for key, value in relations.items():\n",
    "                all_relations[key][\"relation_types\"].update(value[\"relation_types\"])\n",
    "                \n",
    "\n",
    "        except Exception:\n",
    "            pass  \n",
    "\n",
    "    return all_acts, all_relations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "import csv\n",
    "import networkx as nx\n",
    "\n",
    "def export_network_to_csv_only(act_names, relations, output_csv):\n",
    "    \n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        \n",
    "        writer.writerow([\"Source\", \"Target\", \"RelationType\"])\n",
    "        for (source, target), data in relations.items():\n",
    "            relation_types = sorted(data[\"relation_types\"])\n",
    "            label = \", \".join(relation_types)\n",
    "            writer.writerow([source, target, label])\n",
    "\n",
    "        \n",
    "        writer.writerow([])  \n",
    "        writer.writerow([\"List of Acts\"])\n",
    "        for act in sorted(act_names):\n",
    "            writer.writerow([act])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    folder_path = \"C:/path/to/your/folder/C_Network_Acts\" # Replace this with the actual path to your folder\n",
    "    core_act = \"Mental Health (Compulsory Assessment and Treatment) Act 1992\"\n",
    "    official_acts_csv = \"outputlist_All_2.csv\"\n",
    "\n",
    "    compiled_act_patterns = load_official_act_patterns(official_acts_csv)\n",
    "    act_names, relations= process_folder(folder_path, compiled_act_patterns)\n",
    "\n",
    "    export_network_to_csv_only(\n",
    "        act_names,\n",
    "        relations,\n",
    "        \"act_network_version.csv\"\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac9462",
   "metadata": {},
   "source": [
    "Katz Prestige Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "input_csv = \"act_network.csv\"\n",
    "edges_df = pd.read_csv(input_csv)\n",
    "\n",
    "\n",
    "edges_df_cleaned = edges_df.dropna(subset=[\"Source\", \"Target\"])\n",
    "\n",
    "\n",
    "edges_df_cleaned.to_csv(\"cleaned_edge_list.csv\", index=False)\n",
    "\n",
    "\n",
    "G = nx.from_pandas_edgelist(edges_df_cleaned, source='Source', target='Target', create_using=nx.DiGraph())\n",
    "\n",
    "\n",
    "alpha = 0.005\n",
    "katz_centrality = nx.katz_centrality_numpy(G, alpha=alpha)\n",
    "\n",
    "\n",
    "katz_df = pd.DataFrame(katz_centrality.items(), columns=[\"Act\", \"Katz_Prestige\"])\n",
    "\n",
    "\n",
    "katz_df = katz_df.dropna(subset=[\"Act\"])\n",
    "\n",
    "\n",
    "katz_df = katz_df.sort_values(by=\"Katz_Prestige\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "output_csv = \"katz_prestige.csv\"\n",
    "katz_df.to_csv(output_csv, index=False)\n",
    "\n",
    "\n",
    "print(\"Katz Prestige Centrality (cleaned) saved to:\", output_csv)\n",
    "print(\"Top 15 Acts by Katz Prestige:\")\n",
    "print(katz_df.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea0c7e",
   "metadata": {},
   "source": [
    "Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "input_csv = \"act_network.csv\"  \n",
    "output_csv = \"katz_robustness_results.csv\"\n",
    "delete_fractions = [0.01, 0.05, 0.10, 0.20]\n",
    "num_repeats = 100\n",
    "\n",
    "\n",
    "edges_df = pd.read_csv(input_csv)\n",
    "G_original = nx.from_pandas_edgelist(edges_df, source='Source', target='Target', create_using=nx.DiGraph())\n",
    "\n",
    "\n",
    "alpha = 0.005  \n",
    "katz_original = nx.katz_centrality_numpy(G_original, alpha=alpha)\n",
    "katz_orig_rank = pd.Series(katz_original).rank(method=\"min\")\n",
    "\n",
    "\n",
    "results = []\n",
    "for frac in delete_fractions:\n",
    "    for run in range(num_repeats):\n",
    "        G_temp = G_original.copy()\n",
    "        num_edges = int(frac * G_temp.number_of_edges())\n",
    "        removed_edges = random.sample(list(G_temp.edges()), num_edges)\n",
    "        G_temp.remove_edges_from(removed_edges)\n",
    "\n",
    "        try:\n",
    "            katz_temp = nx.katz_centrality_numpy(G_temp, alpha=alpha)\n",
    "            katz_temp_rank = pd.Series(katz_temp).reindex(katz_orig_rank.index).rank(method=\"min\")\n",
    "            corr, _ = pearsonr(katz_orig_rank, katz_temp_rank)\n",
    "        except:\n",
    "            corr = np.nan  \n",
    "\n",
    "        results.append({\n",
    "            \"Fraction_Removed\": frac,\n",
    "            \"Run\": run,\n",
    "            \"Pearson_Correlation\": corr\n",
    "        })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_csv, index=False)\n",
    "print(\"Results saved to\", output_csv)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "results_df.boxplot(column=\"Pearson_Correlation\", by=\"Fraction_Removed\")\n",
    "plt.title(\"Robustness of Katz Prestige Centrality\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Edge Deletion Fraction\")\n",
    "plt.ylabel(\"Pearson Correlation\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"katz_robustness_plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f0e9b",
   "metadata": {},
   "source": [
    "Louvain Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fe430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import defaultdict\n",
    "import community as community_louvain  \n",
    "\n",
    "\n",
    "csv_input = \"act_network.csv\"\n",
    "core_act = \"Mental Health (Compulsory Assessment and Treatment) Act 1992\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_input)\n",
    "G = nx.from_pandas_edgelist(df, \"Source\", \"Target\", edge_attr=True, create_using=nx.Graph())\n",
    "\n",
    "\n",
    "\n",
    "partition = community_louvain.best_partition(G, resolution=1.0)\n",
    "\n",
    "\n",
    "modularity = community_louvain.modularity(partition, G)\n",
    "print(f\"Modularity Score: {modularity:.4f}\")\n",
    "\n",
    "\n",
    "core_comm = partition.get(core_act, \"Not Found\")\n",
    "print(f\"Core Act '{core_act}' is in Community: {core_comm}\")\n",
    "\n",
    "\n",
    "communities = defaultdict(list)\n",
    "for node, cid in partition.items():\n",
    "    communities[cid].append(node)\n",
    "\n",
    "community_df = pd.DataFrame([(cid, act) for cid, acts in communities.items() for act in acts],\n",
    "                            columns=[\"Community\", \"ActName\"])\n",
    "community_df.to_csv(\"community_ids_with_act_names.csv\", index=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "base_cmap = plt.get_cmap(\"tab20\")\n",
    "colors = lambda i: base_cmap(i % base_cmap.N)\n",
    "node_colors = [colors(partition[node]) for node in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=20, alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, edge_color=\"gray\", width=0.5, alpha=0.4)\n",
    "plt.title(\"Louvain Community Detection for NZ Mental Health Act Network\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.savefig(\"louvain_community_network.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, len(communities) * 0.3))  \n",
    "fig.subplots_adjust(left=0.2)\n",
    "\n",
    "patches = [mpatches.Patch(color=colors(i), label=f\"Community {i}\") for i in sorted(communities.keys())]\n",
    "legend = ax.legend(handles=patches, loc='center left', fontsize=10, frameon=False)\n",
    "\n",
    "ax.axis('off')  \n",
    "plt.title(\"Community Color Legend\", fontsize=12)\n",
    "plt.savefig(\"community_legend.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "G_proj = nx.Graph()\n",
    "for cid, nodes in communities.items():\n",
    "    G_proj.add_node(cid, size=len(nodes))\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    cu = partition[u]\n",
    "    cv = partition[v]\n",
    "    if cu != cv:\n",
    "        if G_proj.has_edge(cu, cv):\n",
    "            G_proj[cu][cv]['weight'] += 1\n",
    "        else:\n",
    "            G_proj.add_edge(cu, cv, weight=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5.5, 6))\n",
    "proj_pos = nx.spring_layout(G_proj, seed=42, k=1.2)\n",
    "proj_colors = [colors(n) for n in G_proj.nodes()]\n",
    "proj_sizes = [G_proj.nodes[n]['size'] * 10 for n in G_proj.nodes()]\n",
    "edge_widths = [G_proj[u][v]['weight'] / 10 for u, v in G_proj.edges()]\n",
    "nx.draw(G_proj, proj_pos, with_labels=True, node_color=proj_colors,\n",
    "        node_size=proj_sizes, width=edge_widths, edge_color='black', alpha=0.8)\n",
    "plt.title(\"Community Projection Graph of NZ Mental Health Act Network\", fontsize=13)\n",
    "plt.savefig(\"community_projection_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3208f1",
   "metadata": {},
   "source": [
    "Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5edcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import community as community_louvain \n",
    "\n",
    "\n",
    "community_df = pd.read_csv(\"community_ids_with_act_names.csv\")\n",
    "edges_df = pd.read_csv(\"act_network.csv\")\n",
    "G = nx.from_pandas_edgelist(edges_df, \"Source\", \"Target\")\n",
    "\n",
    "\n",
    "\n",
    "core_act = \"Mental Health (Compulsory Assessment and Treatment) Act 1992\"\n",
    "\n",
    "partition = {row[\"ActName\"]: row[\"Community\"] for _, row in community_df.iterrows()}\n",
    "modularity = community_louvain.modularity(partition, G)\n",
    "print(f\"Modularity Score: {modularity:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "community_nodes = {}\n",
    "for _, row in community_df.iterrows():\n",
    "    community_nodes.setdefault(row[\"Community\"], set()).add(row[\"ActName\"])\n",
    "\n",
    "G_proj = nx.Graph()\n",
    "for c1, nodes1 in community_nodes.items():\n",
    "    for c2, nodes2 in community_nodes.items():\n",
    "        if c1 < c2 and any(G.has_edge(n1, n2) for n1 in nodes1 for n2 in nodes2):\n",
    "            G_proj.add_edge(c1, c2)\n",
    "\n",
    "\n",
    "adj_matrix = nx.to_numpy_array(G_proj, nodelist=sorted(G_proj.nodes()))\n",
    "distance_matrix = 1 - adj_matrix\n",
    "community_ids = sorted(G_proj.nodes())\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=8, metric='precomputed', linkage='average')\n",
    "macro_labels = clustering.fit_predict(distance_matrix)\n",
    "macro_comm_map = {comm: macro for comm, macro in zip(community_ids, macro_labels)}\n",
    "community_df[\"Macro_Community\"] = community_df[\"Community\"].map(macro_comm_map)\n",
    "\n",
    "\n",
    "\n",
    "core_macro_comm = community_df.loc[community_df[\"ActName\"] == core_act, \"Macro_Community\"].values\n",
    "if len(core_macro_comm) > 0:\n",
    "    print(f\"Core Act '{core_act}' is in Macro Community: {core_macro_comm[0]}\")\n",
    "else:\n",
    "    print(f\"Core Act '{core_act}' not found in the dataset.\")\n",
    "\n",
    "\n",
    "community_df.to_csv(\"macro_communities.csv\", index=False)\n",
    "macro_groups = community_df.groupby(\"Macro_Community\")[\"ActName\"].apply(list)\n",
    "pd.DataFrame([\n",
    "    {\"Macro_Community\": m, \"Acts\": \"; \".join(str(a) for a in acts if pd.notna(a))}\n",
    "    for m, acts in macro_groups.items()\n",
    "]).to_csv(\"macro_community_groups.csv\", index=False)\n",
    "\n",
    "\n",
    "# === Color Mapping\n",
    "macro_ids = sorted(set(macro_labels))\n",
    "cmap = cm.tab10\n",
    "macro_color_dict = {m: cmap(i % 10) for i, m in enumerate(macro_ids)}\n",
    "act_macro_map = dict(zip(community_df[\"ActName\"], community_df[\"Macro_Community\"]))\n",
    "\n",
    "# === Plot: Full Network by Macro-Community ===\n",
    "plt.figure(figsize=(9, 7))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "node_colors = [macro_color_dict.get(act_macro_map.get(n, -1), \"grey\") for n in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=8)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.04)\n",
    "plt.title(\"Macro-Community Detection for NZ Mental Health Act Network\", fontsize=11)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Macro-Community.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, len(macro_ids) * 0.3))  \n",
    "fig.subplots_adjust(left=0.2)\n",
    "\n",
    "patches = [\n",
    "    mpatches.Patch(color=macro_color_dict[i], label=f\"Macro Community {i}\")\n",
    "    for i in sorted(macro_ids)\n",
    "]\n",
    "\n",
    "legend = ax.legend(handles=patches, loc='center left', fontsize=10, frameon=False)\n",
    "\n",
    "ax.axis('off')  \n",
    "plt.title(\"Macro-Community Color Legend\", fontsize=12)\n",
    "plt.savefig(\"macro_community_legend.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "macro_nodes = community_df.groupby(\"Macro_Community\")[\"ActName\"].apply(set).to_dict()\n",
    "G_proj_macro = nx.Graph()\n",
    "\n",
    "for i, mi in enumerate(macro_ids):\n",
    "    for mj in macro_ids[i + 1:]:\n",
    "        edge_count = sum(\n",
    "            1 for a1 in macro_nodes[mi]\n",
    "              for a2 in macro_nodes[mj]\n",
    "              if G.has_edge(a1, a2)\n",
    "        )\n",
    "        if edge_count > 0:\n",
    "            G_proj_macro.add_edge(mi, mj, weight=edge_count)\n",
    "\n",
    "\n",
    "\n",
    "macro_sizes = [len(macro_nodes[m]) * 2 for m in G_proj_macro.nodes()]\n",
    "macro_colors = [macro_color_dict[m] for m in G_proj_macro.nodes()]\n",
    "edge_widths = [G_proj_macro[u][v]['weight'] /22 for u, v in G_proj_macro.edges()]\n",
    "\n",
    "plt.figure(figsize=(5.5, 6))\n",
    "pos = nx.spring_layout(G_proj_macro, seed=42, scale=5, k=1.2)\n",
    "\n",
    "nx.draw(\n",
    "    G_proj_macro,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_size=macro_sizes,\n",
    "    node_color=macro_colors,\n",
    "    width=edge_widths,\n",
    "    edge_color=\"black\",\n",
    "    font_size=8\n",
    ")\n",
    "\n",
    "plt.title(\"Community Projection Graph of NZ Mental Health Act Network\", fontsize=10)\n",
    "plt.axis(\"off\")\n",
    "plt.margins(0.15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"macro_community_projection.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e8f37",
   "metadata": {},
   "source": [
    "Content Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "lda_df = pd.read_csv(\"lda_keyword_top20_per_macro_community.csv\")\n",
    "\n",
    "\n",
    "committee_keywords = {\n",
    "    \"Social Services and Community\": {\n",
    "        \"social\", \"housing\", \"income\", \"women\", \"children\", \"youth\", \"seniors\",\n",
    "        \"pacific\", \"ethnic\", \"arts\", \"culture\", \"heritage\", \"sport\", \"recreation\", \"voluntary\"\n",
    "    },\n",
    "    \"Economic Development, Science and Innovation\": {\n",
    "        \"business\", \"tourism\", \"minerals\", \"commerce\", \"consumer\", \"research\", \"science\",\n",
    "        \"innovation\", \"intellectual\", \"broadcasting\", \"communications\", \"technology\", \"trade\",\n",
    "        \"company\", \"patent\", \"cooperative\", \"store\", \"institute\", \"policy\"\n",
    "    },\n",
    "    \"Finance and Expenditure\": {\n",
    "        \"fiscal\", \"tax\", \"revenue\", \"bank\", \"superannuation\", \"insurance\", \"audit\", \"finance\",\n",
    "        \"fund\", \"financial\", \"accountant\", \"reporting\", \"estate\", \"coverage\"\n",
    "    },\n",
    "    \"Governance and Administration\": {\n",
    "        \"legislation\", \"prime\", \"statistics\", \"internal\", \"affairs\", \"civil\", \"local\",\n",
    "        \"regulations\", \"ombudsman\", \"parliamentary\", \"government\", \"commissioner\", \"council\", \"ministry\"\n",
    "    },\n",
    "    \"Education and Workforce\": {\n",
    "        \"education\", \"training\", \"employment\", \"immigration\", \"workplace\", \"industrial\", \"safety\",\n",
    "        \"worker\", \"employ\", \"parental\", \"leave\", \"protection\", \"relation\",\"wage\", \"contractor\", \"lien\", \"earnings\"\n",
    "    },\n",
    "    \"Justice\": {\n",
    "        \"justice\", \"court\", \"crime\", \"police\", \"corrections\", \"legal\", \"human\", \"rights\",\n",
    "        \"criminal\", \"proceeding\", \"offense\", \"tribunal\", \"person\"\n",
    "    },\n",
    "    \"Primary Production\": {\n",
    "        \"agriculture\", \"biosecurity\", \"fisheries\", \"forestry\", \"land\", \"farming\"\n",
    "    },\n",
    "    \"Transport and Infrastructure\": {\n",
    "        \"transport\", \"road\", \"rail\", \"infrastructure\", \"energy\", \"building\", \"construction\",\n",
    "        \"vehicle\", \"management\", \"conveyance\", \"direction\"\n",
    "    },\n",
    "    \"Foreign Affairs, Defence and Trade\": {\n",
    "        \"customs\", \"defence\", \"foreign\", \"trade\", \"arms\", \"veterans\", \"excise\",\n",
    "        \"duty\", \"tariff\", \"countervailing\"\n",
    "    },\n",
    "    \"Environment\": {\n",
    "        \"conservation\", \"environment\", \"climate\"\n",
    "    },\n",
    "    \"Health\": {\n",
    "        \"health\", \"hospital\", \"medicine\", \"disability\", \"mental\", \"wellness\",\n",
    "        \"infirmary\", \"disablement\"\n",
    "    },\n",
    "    \"Māori Affairs\": {\n",
    "        \"māori\", \"settlement\", \"land\", \"maori\", \"reserve\", \"river\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "community_keywords = defaultdict(set)\n",
    "\n",
    "for _, row in lda_df.iterrows():\n",
    "    community = row[\"Macro_Community\"]\n",
    "    keywords = [str(row[f\"Keyword_{i}\"]).lower().strip() for i in range(1, 21) if pd.notna(row[f\"Keyword_{i}\"])]\n",
    "    community_keywords[community].update(keywords)\n",
    "\n",
    "\n",
    "output_rows = []\n",
    "\n",
    "for comm_id, lda_words in community_keywords.items():\n",
    "    for committee, keywords in committee_keywords.items():\n",
    "        norm_keywords = {kw.lower().strip() for kw in keywords}\n",
    "        overlap = norm_keywords & lda_words\n",
    "        score = len(overlap) / len(norm_keywords) if norm_keywords else 0\n",
    "        output_rows.append({\n",
    "            \"Macro Community ID\": comm_id,\n",
    "            \"Parliamentary Committee\": committee,\n",
    "            \"Similarity Score\": round(score, 3),\n",
    "            \"Overlap Terms\": \", \".join(sorted(overlap))\n",
    "        })\n",
    "\n",
    "\n",
    "df_output = pd.DataFrame(output_rows)\n",
    "df_output.sort_values(by=[\"Macro Community ID\", \"Similarity Score\"], ascending=[True, False], inplace=True)\n",
    "df_output.to_csv(\"macro_committee_similarity_LDA.csv\", index=False)\n",
    "print(df_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
